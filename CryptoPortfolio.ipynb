{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read training data\n",
    "import pandas as pd\n",
    "fileName = \"trainData.csv\"\n",
    "df = pd.read_csv(fileName, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>O</th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>BV</th>\n",
       "      <th>Mean</th>\n",
       "      <th>T</th>\n",
       "      <th>MarketName</th>\n",
       "      <th>Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.018060</td>\n",
       "      <td>0.012889</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>-0.009781</td>\n",
       "      <td>0.838961</td>\n",
       "      <td>0.849676</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>BTC-LTC</td>\n",
       "      <td>0.118046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>-0.017773</td>\n",
       "      <td>-0.009005</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>-0.295003</td>\n",
       "      <td>-0.300707</td>\n",
       "      <td>-0.003464</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>BTC-LTC</td>\n",
       "      <td>-0.346367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.016522</td>\n",
       "      <td>0.026429</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>0.007197</td>\n",
       "      <td>-0.238974</td>\n",
       "      <td>-0.232854</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>BTC-LTC</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.021972</td>\n",
       "      <td>-0.024771</td>\n",
       "      <td>-0.014549</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.643869</td>\n",
       "      <td>0.634503</td>\n",
       "      <td>-0.006758</td>\n",
       "      <td>2015-12-18</td>\n",
       "      <td>BTC-LTC</td>\n",
       "      <td>-0.675804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.020528</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>-0.016248</td>\n",
       "      <td>-0.002521</td>\n",
       "      <td>-0.855318</td>\n",
       "      <td>-0.856800</td>\n",
       "      <td>-0.009483</td>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>BTC-LTC</td>\n",
       "      <td>-0.948274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         O         C         H         L         V        BV      Mean  \\\n",
       "0   4 -0.018060  0.012889  0.011777 -0.009781  0.838961  0.849676  0.001180   \n",
       "1   4  0.011609 -0.017773 -0.009005  0.002394 -0.295003 -0.300707 -0.003464   \n",
       "2   4 -0.016522  0.026429  0.007796  0.007197 -0.238974 -0.232854  0.007503   \n",
       "3   4  0.021972 -0.024771 -0.014549  0.001388  0.643869  0.634503 -0.006758   \n",
       "4   4 -0.020528  0.003278 -0.016248 -0.002521 -0.855318 -0.856800 -0.009483   \n",
       "\n",
       "            T MarketName    Reward  \n",
       "0  2015-12-15    BTC-LTC  0.118046  \n",
       "1  2015-12-16    BTC-LTC -0.346367  \n",
       "2  2015-12-17    BTC-LTC  0.750303  \n",
       "3  2015-12-18    BTC-LTC -0.675804  \n",
       "4  2015-12-19    BTC-LTC -0.948274  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['T','O','C','H','L','V','BV']\n",
    "reward_cols = ['T','Reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth = df[(df['MarketName'] == 'BTC-ETH')][colnames]\n",
    "xrp = df[(df['MarketName'] == 'BTC-XRP')][colnames]\n",
    "ltc = df[(df['MarketName'] == 'BTC-LTC')][colnames]\n",
    "xlm = df[(df['MarketName'] == 'BTC-XLM')][colnames]\n",
    "usd = df[(df['MarketName'] == 'USDT-BTC')][colnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>O</th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>BV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>-0.023044</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>-0.016174</td>\n",
       "      <td>0.419006</td>\n",
       "      <td>0.411878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>-0.036503</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.040730</td>\n",
       "      <td>-0.032838</td>\n",
       "      <td>0.500554</td>\n",
       "      <td>0.485358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>-0.063636</td>\n",
       "      <td>-0.078651</td>\n",
       "      <td>-0.048164</td>\n",
       "      <td>-0.394836</td>\n",
       "      <td>-0.423502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2015-12-18</td>\n",
       "      <td>-0.063636</td>\n",
       "      <td>-0.041748</td>\n",
       "      <td>-0.068826</td>\n",
       "      <td>-0.005056</td>\n",
       "      <td>-0.407574</td>\n",
       "      <td>-0.437244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>-0.041748</td>\n",
       "      <td>-0.009620</td>\n",
       "      <td>-0.030636</td>\n",
       "      <td>-0.032878</td>\n",
       "      <td>0.105960</td>\n",
       "      <td>0.092657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               T         O         C         H         L         V        BV\n",
       "1235  2015-12-15  0.015275 -0.023044 -0.002150 -0.016174  0.419006  0.411878\n",
       "1236  2015-12-16 -0.036503  0.001192  0.040730 -0.032838  0.500554  0.485358\n",
       "1237  2015-12-17  0.015463 -0.063636 -0.078651 -0.048164 -0.394836 -0.423502\n",
       "1238  2015-12-18 -0.063636 -0.041748 -0.068826 -0.005056 -0.407574 -0.437244\n",
       "1239  2015-12-19 -0.041748 -0.009620 -0.030636 -0.032878  0.105960  0.092657"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_reward = df[(df['MarketName'] == 'BTC-ETH')][reward_cols]\n",
    "xrp_reward = df[(df['MarketName'] == 'BTC-XRP')][reward_cols]\n",
    "ltc_reward = df[(df['MarketName'] == 'BTC-LTC')][reward_cols]\n",
    "xlm_reward = df[(df['MarketName'] == 'BTC-XLM')][reward_cols]\n",
    "usd_reward = df[(df['MarketName'] == 'USDT-BTC')][reward_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>-0.896561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>0.523557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>-6.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2015-12-18</td>\n",
       "      <td>-3.870695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>-3.173201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               T    Reward\n",
       "1235  2015-12-15 -0.896561\n",
       "1236  2015-12-16  0.523557\n",
       "1237  2015-12-17 -6.449900\n",
       "1238  2015-12-18 -3.870695\n",
       "1239  2015-12-19 -3.173201"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_reward.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>O_eth</th>\n",
       "      <th>C_eth</th>\n",
       "      <th>H_eth</th>\n",
       "      <th>L_eth</th>\n",
       "      <th>V_eth</th>\n",
       "      <th>BV_eth</th>\n",
       "      <th>O_xrp</th>\n",
       "      <th>C_xrp</th>\n",
       "      <th>H_xrp</th>\n",
       "      <th>...</th>\n",
       "      <th>H_xlm</th>\n",
       "      <th>L_xlm</th>\n",
       "      <th>V_xlm</th>\n",
       "      <th>BV_xlm</th>\n",
       "      <th>O</th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>BV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>-0.023044</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>-0.016174</td>\n",
       "      <td>0.419006</td>\n",
       "      <td>0.411878</td>\n",
       "      <td>-0.250256</td>\n",
       "      <td>-0.100416</td>\n",
       "      <td>-0.212046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043933</td>\n",
       "      <td>-0.144351</td>\n",
       "      <td>1029.180334</td>\n",
       "      <td>885.502597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1320.637261</td>\n",
       "      <td>1410.396749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>-0.036503</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.040730</td>\n",
       "      <td>-0.032838</td>\n",
       "      <td>0.500554</td>\n",
       "      <td>0.485358</td>\n",
       "      <td>-0.111491</td>\n",
       "      <td>0.131640</td>\n",
       "      <td>-0.027795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.521941</td>\n",
       "      <td>-0.507073</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.815032</td>\n",
       "      <td>-0.810448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>-0.063636</td>\n",
       "      <td>-0.078651</td>\n",
       "      <td>-0.048164</td>\n",
       "      <td>-0.394836</td>\n",
       "      <td>-0.423502</td>\n",
       "      <td>0.131640</td>\n",
       "      <td>-0.024490</td>\n",
       "      <td>-0.025341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.992587</td>\n",
       "      <td>-0.992851</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.815032</td>\n",
       "      <td>-0.810448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-18</td>\n",
       "      <td>-0.063636</td>\n",
       "      <td>-0.041748</td>\n",
       "      <td>-0.068826</td>\n",
       "      <td>-0.005056</td>\n",
       "      <td>-0.407574</td>\n",
       "      <td>-0.437244</td>\n",
       "      <td>-0.040816</td>\n",
       "      <td>-0.056485</td>\n",
       "      <td>-0.054000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058680</td>\n",
       "      <td>0.019560</td>\n",
       "      <td>1.314162</td>\n",
       "      <td>1.401100</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.999841</td>\n",
       "      <td>-0.999841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>-0.041748</td>\n",
       "      <td>-0.009620</td>\n",
       "      <td>-0.030636</td>\n",
       "      <td>-0.032878</td>\n",
       "      <td>0.105960</td>\n",
       "      <td>0.092657</td>\n",
       "      <td>-0.036879</td>\n",
       "      <td>-0.002956</td>\n",
       "      <td>-0.038055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053118</td>\n",
       "      <td>-0.098321</td>\n",
       "      <td>11.826813</td>\n",
       "      <td>10.635375</td>\n",
       "      <td>-0.017429</td>\n",
       "      <td>-0.017429</td>\n",
       "      <td>-0.017429</td>\n",
       "      <td>-0.017429</td>\n",
       "      <td>863.027096</td>\n",
       "      <td>847.967800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            T     O_eth     C_eth     H_eth     L_eth     V_eth    BV_eth  \\\n",
       "0  2015-12-15  0.015275 -0.023044 -0.002150 -0.016174  0.419006  0.411878   \n",
       "1  2015-12-16 -0.036503  0.001192  0.040730 -0.032838  0.500554  0.485358   \n",
       "2  2015-12-17  0.015463 -0.063636 -0.078651 -0.048164 -0.394836 -0.423502   \n",
       "3  2015-12-18 -0.063636 -0.041748 -0.068826 -0.005056 -0.407574 -0.437244   \n",
       "4  2015-12-19 -0.041748 -0.009620 -0.030636 -0.032878  0.105960  0.092657   \n",
       "\n",
       "      O_xrp     C_xrp     H_xrp  ...     H_xlm     L_xlm        V_xlm  \\\n",
       "0 -0.250256 -0.100416 -0.212046  ... -0.043933 -0.144351  1029.180334   \n",
       "1 -0.111491  0.131640 -0.027795  ... -0.052516  0.000000    -0.521941   \n",
       "2  0.131640 -0.024490 -0.025341  ... -0.055427  0.000000    -0.992587   \n",
       "3 -0.040816 -0.056485 -0.054000  ...  0.058680  0.019560     1.314162   \n",
       "4 -0.036879 -0.002956 -0.038055  ... -0.053118 -0.098321    11.826813   \n",
       "\n",
       "       BV_xlm         O         C         H         L            V  \\\n",
       "0  885.502597  0.000000  0.071429  0.071429  0.000000  1320.637261   \n",
       "1   -0.507073  0.071429  0.002222  0.044444  0.071429    -0.815032   \n",
       "2   -0.992851  0.071429  0.002222  0.044444  0.071429    -0.815032   \n",
       "3    1.401100  0.020000  0.017738 -0.023404  0.020000    -0.999841   \n",
       "4   10.635375 -0.017429 -0.017429 -0.017429 -0.017429   863.027096   \n",
       "\n",
       "            BV  \n",
       "0  1410.396749  \n",
       "1    -0.810448  \n",
       "2    -0.810448  \n",
       "3    -0.999841  \n",
       "4   847.967800  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged1 = pd.merge(eth, xrp, on = 'T', suffixes=('_eth', '_xrp'))\n",
    "merged2 = pd.merge(ltc, xlm, on = 'T', suffixes=('_ltc', '_xlm'))\n",
    "merged = pd.merge(merged1, merged2, on = 'T')\n",
    "merged = pd.merge(merged, usd, on = 'T')\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCEMENT LEARNING SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 50\n",
    "\n",
    "class TradingAction(object):\n",
    "    ETH = 0\n",
    "    XRP = 1\n",
    "    LTC = 2\n",
    "    XLM = 3\n",
    "    USD = 4\n",
    "    \n",
    "class TradingEnv:\n",
    "  def __init__(self):\n",
    "    #Actions : 0. eth, 1. xrp, 2. ltc, 3. xlm, 4. usd \n",
    "    pass\n",
    "\n",
    "  def reset(self):\n",
    "    pass\n",
    "\n",
    "  def __init__(self):\n",
    "    #Actions : 0. eth, 1. xrp, 2. ltc, 3. xlm, 4. usd \n",
    "    pass\n",
    "\n",
    "  def step(self, action, date):\n",
    "    reward = 0\n",
    "    if action == TradingAction.ETH:\n",
    "        reward = eth_reward[(eth_reward['T'] == date)]['Reward']\n",
    "    if action == TradingAction.XRP:\n",
    "        reward = xrp_reward[(xrp_reward['T'] == date)]['Reward']\n",
    "    if action == TradingAction.LTC:\n",
    "        reward = ltc_reward[(ltc_reward['T'] == date)]['Reward']\n",
    "    if action == TradingAction.XLM:\n",
    "        reward = xlm_reward[(xlm_reward['T'] == date)]['Reward']\n",
    "    if action == TradingAction.USD:\n",
    "        reward = usd_reward[(usd_reward['T'] == date)]['Reward']\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                temp_pred = np.amax(self.model.predict(next_state)[0])\n",
    "                target = (reward + self.gamma * temp_pred)\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>O_eth</th>\n",
       "      <th>C_eth</th>\n",
       "      <th>H_eth</th>\n",
       "      <th>L_eth</th>\n",
       "      <th>V_eth</th>\n",
       "      <th>BV_eth</th>\n",
       "      <th>O_xrp</th>\n",
       "      <th>C_xrp</th>\n",
       "      <th>H_xrp</th>\n",
       "      <th>...</th>\n",
       "      <th>H_xlm</th>\n",
       "      <th>L_xlm</th>\n",
       "      <th>V_xlm</th>\n",
       "      <th>BV_xlm</th>\n",
       "      <th>O</th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>BV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>-0.012529</td>\n",
       "      <td>-0.012618</td>\n",
       "      <td>-0.023630</td>\n",
       "      <td>-0.013846</td>\n",
       "      <td>0.510812</td>\n",
       "      <td>0.475972</td>\n",
       "      <td>-0.003773</td>\n",
       "      <td>-0.003555</td>\n",
       "      <td>-0.004609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025793</td>\n",
       "      <td>-0.003682</td>\n",
       "      <td>-0.410088</td>\n",
       "      <td>-0.430252</td>\n",
       "      <td>-0.005227</td>\n",
       "      <td>-0.021530</td>\n",
       "      <td>-0.001743</td>\n",
       "      <td>-0.030729</td>\n",
       "      <td>1.592960</td>\n",
       "      <td>1.522386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>-0.013927</td>\n",
       "      <td>0.048061</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>0.402531</td>\n",
       "      <td>0.438517</td>\n",
       "      <td>-0.006842</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027344</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>-0.109622</td>\n",
       "      <td>-0.110559</td>\n",
       "      <td>-0.023666</td>\n",
       "      <td>0.036065</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.850213</td>\n",
       "      <td>0.876401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>0.050062</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.035901</td>\n",
       "      <td>-0.135164</td>\n",
       "      <td>-0.115009</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008032</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.534653</td>\n",
       "      <td>-0.537858</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.030229</td>\n",
       "      <td>-0.642258</td>\n",
       "      <td>-0.634037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>-0.009956</td>\n",
       "      <td>-0.007603</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>-0.205628</td>\n",
       "      <td>-0.207156</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>-0.013315</td>\n",
       "      <td>-0.012998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004049</td>\n",
       "      <td>-0.001836</td>\n",
       "      <td>0.415438</td>\n",
       "      <td>0.412235</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.007860</td>\n",
       "      <td>0.346091</td>\n",
       "      <td>0.354345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>-0.006622</td>\n",
       "      <td>-0.019513</td>\n",
       "      <td>-0.012309</td>\n",
       "      <td>-0.030286</td>\n",
       "      <td>0.030882</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>-0.013919</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>-0.013413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034327</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>1.452174</td>\n",
       "      <td>1.517361</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.002567</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>-0.014817</td>\n",
       "      <td>0.483838</td>\n",
       "      <td>0.487514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               T     O_eth     C_eth     H_eth     L_eth     V_eth    BV_eth  \\\n",
       "1175  2019-03-04 -0.012529 -0.012618 -0.023630 -0.013846  0.510812  0.475972   \n",
       "1176  2019-03-05 -0.013927  0.048061  0.036362  0.010416  0.402531  0.438517   \n",
       "1177  2019-03-06  0.050062  0.005023  0.015115  0.035901 -0.135164 -0.115009   \n",
       "1178  2019-03-07  0.000995 -0.009956 -0.007603  0.006653 -0.205628 -0.207156   \n",
       "1179  2019-03-08 -0.006622 -0.019513 -0.012309 -0.030286  0.030882  0.017551   \n",
       "\n",
       "         O_xrp     C_xrp     H_xrp  ...     H_xlm     L_xlm     V_xlm  \\\n",
       "1175 -0.003773 -0.003555 -0.004609  ... -0.025793 -0.003682 -0.410088   \n",
       "1176 -0.006842  0.003690  0.004874  ... -0.027344  0.007852 -0.109622   \n",
       "1177  0.003690  0.003309  0.007518  ... -0.008032 -0.001375 -0.534653   \n",
       "1178  0.003799 -0.013315 -0.012998  ... -0.004049 -0.001836  0.415438   \n",
       "1179 -0.013919 -0.015105 -0.013413  ...  0.034327  0.011494  1.452174   \n",
       "\n",
       "        BV_xlm         O         C         H         L         V        BV  \n",
       "1175 -0.430252 -0.005227 -0.021530 -0.001743 -0.030729  1.592960  1.522386  \n",
       "1176 -0.110559 -0.023666  0.036065  0.012803  0.009537  0.850213  0.876401  \n",
       "1177 -0.537858  0.037675  0.004008  0.004364  0.030229 -0.642258 -0.634037  \n",
       "1178  0.412235  0.002449  0.003125  0.002387  0.007860  0.346091  0.354345  \n",
       "1179  1.517361  0.003125 -0.002567  0.006259 -0.014817  0.483838  0.487514  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split as Train and Test data\n",
    "row_count = merged.shape[0]\n",
    "split_point = int(row_count - 60)\n",
    "train_data, test_data = merged[:split_point], merged[split_point:]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, best_reward: 591.3503079885982, total_reward: 555.8445727608567\n",
      "episode: 1, best_reward: 591.3503079885982, total_reward: 180.76353121347395\n",
      "episode: 2, best_reward: 602.073500322238, total_reward: 444.242491640371\n",
      "episode: 3, best_reward: 1324.9316336016655, total_reward: 1267.723638138432\n",
      "episode: 4, best_reward: 1607.462554219562, total_reward: 1586.8928016761365\n",
      "episode: 5, best_reward: 1989.6145845719516, total_reward: 1953.286233121661\n",
      "episode: 6, best_reward: 2290.937860557114, total_reward: 2289.1924098797795\n",
      "episode: 7, best_reward: 2491.5258136060693, total_reward: 2483.9136050741618\n",
      "episode: 8, best_reward: 2491.5258136060693, total_reward: 2426.694660701037\n",
      "episode: 9, best_reward: 2491.5258136060693, total_reward: 1746.2940670106493\n",
      "episode: 10, best_reward: 2491.5258136060693, total_reward: 1961.22972363088\n",
      "episode: 11, best_reward: 2685.535280848861, total_reward: 2682.6306479562786\n",
      "episode: 12, best_reward: 2685.535280848861, total_reward: 2256.8032152867\n",
      "episode: 13, best_reward: 2685.535280848861, total_reward: 1206.4119445201131\n",
      "episode: 14, best_reward: 2685.535280848861, total_reward: 974.7430477313582\n",
      "episode: 15, best_reward: 2685.535280848861, total_reward: 1729.72183911439\n",
      "episode: 16, best_reward: 2685.535280848861, total_reward: 1964.8200488322645\n",
      "episode: 17, best_reward: 2685.535280848861, total_reward: 2227.7702352085357\n",
      "episode: 18, best_reward: 2685.535280848861, total_reward: 2402.322343425189\n",
      "episode: 19, best_reward: 2685.535280848861, total_reward: 1721.945238682095\n",
      "episode: 20, best_reward: 2685.535280848861, total_reward: 1819.902424240547\n",
      "episode: 21, best_reward: 2685.535280848861, total_reward: 1799.535546441848\n",
      "episode: 22, best_reward: 2685.535280848861, total_reward: 1533.27796315727\n",
      "episode: 23, best_reward: 2685.535280848861, total_reward: 1757.825864568215\n",
      "episode: 24, best_reward: 2685.535280848861, total_reward: 1493.9984416462664\n",
      "episode: 25, best_reward: 2685.535280848861, total_reward: 1141.759094599239\n",
      "episode: 26, best_reward: 2685.535280848861, total_reward: 791.198899514287\n",
      "episode: 27, best_reward: 2685.535280848861, total_reward: 710.7429470853652\n",
      "episode: 28, best_reward: 2685.535280848861, total_reward: 668.5757983595361\n",
      "episode: 29, best_reward: 2685.535280848861, total_reward: 999.3899017181184\n",
      "episode: 30, best_reward: 2685.535280848861, total_reward: 651.5474228189431\n",
      "episode: 31, best_reward: 2685.535280848861, total_reward: 446.3194375835435\n",
      "episode: 32, best_reward: 2685.535280848861, total_reward: 1380.2660201234064\n",
      "episode: 33, best_reward: 2685.535280848861, total_reward: 520.2887627227475\n",
      "episode: 34, best_reward: 2685.535280848861, total_reward: 831.1058322669768\n",
      "episode: 35, best_reward: 2685.535280848861, total_reward: 791.8872714939522\n",
      "episode: 36, best_reward: 2685.535280848861, total_reward: 889.6373499944121\n",
      "episode: 37, best_reward: 2685.535280848861, total_reward: 638.9347239519051\n",
      "episode: 38, best_reward: 2685.535280848861, total_reward: 1124.5480751673567\n",
      "episode: 39, best_reward: 2685.535280848861, total_reward: 1154.9884355431843\n",
      "episode: 40, best_reward: 2685.535280848861, total_reward: 1455.5108290966866\n",
      "episode: 41, best_reward: 2685.535280848861, total_reward: 1396.9480306983635\n",
      "episode: 42, best_reward: 2685.535280848861, total_reward: 1224.7709976221706\n",
      "episode: 43, best_reward: 2685.535280848861, total_reward: 1137.1711049789867\n",
      "episode: 44, best_reward: 2685.535280848861, total_reward: 1251.2185627280155\n",
      "episode: 45, best_reward: 2685.535280848861, total_reward: 1045.4246881181364\n",
      "episode: 46, best_reward: 2685.535280848861, total_reward: 1044.5909038794405\n",
      "episode: 47, best_reward: 2685.535280848861, total_reward: 822.8820362792119\n",
      "episode: 48, best_reward: 2685.535280848861, total_reward: 885.7010739090913\n",
      "episode: 49, best_reward: 2685.535280848861, total_reward: 911.6921171828951\n",
      "episode: 50, best_reward: 2685.535280848861, total_reward: 1170.5200654777204\n",
      "episode: 51, best_reward: 2685.535280848861, total_reward: 1205.1712435679447\n",
      "episode: 52, best_reward: 2685.535280848861, total_reward: 967.4963359150003\n",
      "episode: 53, best_reward: 2685.535280848861, total_reward: 1072.6031825313341\n",
      "episode: 54, best_reward: 2685.535280848861, total_reward: 706.7479275174318\n",
      "episode: 55, best_reward: 2685.535280848861, total_reward: 798.3628409521668\n",
      "episode: 56, best_reward: 2685.535280848861, total_reward: 466.4235608070981\n",
      "episode: 57, best_reward: 2685.535280848861, total_reward: 798.6609327354006\n",
      "episode: 58, best_reward: 2685.535280848861, total_reward: 474.8703730140627\n",
      "episode: 59, best_reward: 2685.535280848861, total_reward: 578.3514233660046\n",
      "episode: 60, best_reward: 2685.535280848861, total_reward: 572.1971277818108\n",
      "episode: 61, best_reward: 2685.535280848861, total_reward: 1002.8970955455694\n",
      "episode: 62, best_reward: 2685.535280848861, total_reward: 782.8493954266835\n",
      "episode: 63, best_reward: 2685.535280848861, total_reward: 971.1003011432877\n",
      "episode: 64, best_reward: 2685.535280848861, total_reward: 1136.110848620564\n",
      "episode: 65, best_reward: 2685.535280848861, total_reward: 1008.6362185328809\n",
      "episode: 66, best_reward: 2685.535280848861, total_reward: 291.71973961733283\n",
      "episode: 67, best_reward: 2685.535280848861, total_reward: 705.4633896941187\n",
      "episode: 68, best_reward: 2685.535280848861, total_reward: 385.1948999176099\n",
      "episode: 69, best_reward: 2685.535280848861, total_reward: 447.950104043958\n",
      "episode: 70, best_reward: 2685.535280848861, total_reward: 434.8440047803043\n",
      "episode: 71, best_reward: 2685.535280848861, total_reward: 618.2637272331617\n",
      "episode: 72, best_reward: 2685.535280848861, total_reward: 1000.0595771971542\n",
      "episode: 73, best_reward: 2685.535280848861, total_reward: 839.5758969311336\n",
      "episode: 74, best_reward: 2685.535280848861, total_reward: 688.1069229823132\n",
      "episode: 75, best_reward: 2685.535280848861, total_reward: 903.8687884920137\n",
      "episode: 76, best_reward: 2685.535280848861, total_reward: 829.4608039131566\n",
      "episode: 77, best_reward: 2685.535280848861, total_reward: 841.6712162089707\n",
      "episode: 78, best_reward: 2685.535280848861, total_reward: 577.6318982615938\n",
      "episode: 79, best_reward: 2685.535280848861, total_reward: 666.887396597617\n",
      "episode: 80, best_reward: 2685.535280848861, total_reward: 699.3518281519694\n",
      "episode: 81, best_reward: 2685.535280848861, total_reward: 1083.2653575072877\n",
      "episode: 82, best_reward: 2685.535280848861, total_reward: 933.4263695002821\n",
      "episode: 83, best_reward: 2685.535280848861, total_reward: 1007.2029025820233\n",
      "episode: 84, best_reward: 2685.535280848861, total_reward: 1188.276797751767\n",
      "episode: 85, best_reward: 2685.535280848861, total_reward: 909.0926176923775\n",
      "episode: 86, best_reward: 2685.535280848861, total_reward: 950.3898449806409\n",
      "episode: 87, best_reward: 2685.535280848861, total_reward: 1012.7014509272889\n",
      "episode: 88, best_reward: 2685.535280848861, total_reward: 1111.9961588161548\n",
      "episode: 89, best_reward: 2685.535280848861, total_reward: 922.7311864487282\n",
      "episode: 90, best_reward: 2685.535280848861, total_reward: 1060.3765844594936\n",
      "episode: 91, best_reward: 2685.535280848861, total_reward: 1031.3494087061474\n",
      "episode: 92, best_reward: 2685.535280848861, total_reward: 904.8672986410338\n",
      "episode: 93, best_reward: 2685.535280848861, total_reward: 470.48477607207514\n",
      "episode: 94, best_reward: 2685.535280848861, total_reward: 655.6934430676849\n",
      "episode: 95, best_reward: 2685.535280848861, total_reward: 764.0840132330369\n",
      "episode: 96, best_reward: 2685.535280848861, total_reward: 748.3315830373084\n",
      "episode: 97, best_reward: 2685.535280848861, total_reward: 655.2674623534664\n",
      "episode: 98, best_reward: 2685.535280848861, total_reward: 993.2516090103419\n",
      "episode: 99, best_reward: 2685.535280848861, total_reward: 677.9494252565048\n"
     ]
    }
   ],
   "source": [
    "#TRAIN AGENT\n",
    "observation_cols = ['O_eth','C_eth','H_eth','L_eth','V_eth','BV_eth','O_xrp','C_xrp','H_xrp','L_xrp','V_xrp','BV_xrp','O_ltc','C_ltc','H_ltc','L_ltc','V_ltc','BV_ltc','O_xlm','C_xlm','H_xlm','L_xlm','V_xlm','BV_xlm','O','C','H','L','V','BV']\n",
    "state_size = len(observation_cols)\n",
    "action_size = 5\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "# agent.load(\"./save/trading-dqn.h5\")\n",
    "\n",
    "done = False\n",
    "batch_size = 32\n",
    "best_score = 0\n",
    "best_action = 0\n",
    "best_reward = -100000\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    total_reward = 0\n",
    "    for idx in range(len(train_data)-1):\n",
    "        state = train_data.iloc[idx][observation_cols]\n",
    "        state = np.reshape([state], [1, state_size])\n",
    "        \n",
    "        action = agent.act(state)\n",
    "        reward = env.step(action, train_data.iloc[idx]['T'])\n",
    "        \n",
    "        next_state = train_data.iloc[idx+1][observation_cols]\n",
    "        next_state = np.reshape([next_state], [1, state_size])\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "        total_reward = total_reward + reward.item() \n",
    "        if total_reward >= best_reward:\n",
    "            best_reward = total_reward\n",
    "            best_action = action\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "    print(\"episode: {}, best_reward: {}, total_reward: {}\" .format(e, best_reward, total_reward))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Agent\n",
    "agent.save(\"./save/trading-dqn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_reward: 21.333948207730213\n"
     ]
    }
   ],
   "source": [
    "#TEST AGENT\n",
    "done = False\n",
    "batch_size = 32\n",
    "test_reward = 0\n",
    "reward_list = []\n",
    "for idx in range(len(test_data)):\n",
    "    state = test_data.iloc[idx][observation_cols]\n",
    "    state = np.reshape([state], [1, state_size])\n",
    "\n",
    "    action = agent.act(state)\n",
    "    reward = env.step(action, test_data.iloc[idx]['T'])\n",
    "\n",
    "    test_reward = test_reward + reward.item() \n",
    "    reward_list.append(reward.item())\n",
    "print(\"Test_reward: {}\" .format(test_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot rewards\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.arange(0,len(test_data),1),reward_list, c='b')\n",
    "plt.title('Model test reward')\n",
    "plt.ylabel('Return %')\n",
    "plt.xlabel('Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
